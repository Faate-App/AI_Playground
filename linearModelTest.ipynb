{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"stanford data set/HCMST 2017 fresh sample for public sharing draft v1.1.dta\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "df = df.replace({'Yes': 1, 'No': 0})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "   CaseID  CASEID_NEW      qflag  weight1  weight1_freqwt  weight2  weight1a  \\\n0       2     2014039  Qualified      NaN             NaN   0.8945       NaN   \n1       3     2019003  Qualified   0.9078         71115.0      NaN    0.9026   \n2       5     2145527  Qualified   0.7205         56442.0      NaN    0.7164   \n3       6     2648857  Qualified   1.2597         98682.0   1.3507    1.2524   \n4       7     2623465  Qualified   0.8686         68044.0      NaN    0.8636   \n\n   weight1a_freqwt  weight_combo  weight_combo_freqwt  ...  \\\n0              NaN      0.277188              19240.0  ...   \n1          70707.0      1.020621              70841.0  ...   \n2          56121.0      0.810074              56227.0  ...   \n3          98110.0      0.418556              29052.0  ...   \n4          67652.0      0.976522              67781.0  ...   \n\n   hcm2017q24_met_through_family hcm2017q24_met_through_friend  \\\n0                             no                            no   \n1                             no                            no   \n2                             no                            no   \n3                             no                            no   \n4                             no                            no   \n\n  hcm2017q24_met_through_as_nghbrs hcm2017q24_met_as_through_cowork  \\\n0                               no                               no   \n1                               no                              yes   \n2                               no                               no   \n3                               no                               no   \n4                              yes                               no   \n\n  w6_subject_race interracial_5cat partner_mother_yrsed subject_mother_yrsed  \\\n0           White               no                 12.0                 14.0   \n1           White               no                 12.0                 16.0   \n2           White               no                  9.0                  7.5   \n3           White               no                 16.0                 12.0   \n4           White               no                 14.0                 17.0   \n\n  partner_yrsed subject_yrsed  \n0          12.0          14.0  \n1          17.0          17.0  \n2          14.0          17.0  \n3          12.0          12.0  \n4          16.0          16.0  \n\n[5 rows x 285 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CaseID</th>\n      <th>CASEID_NEW</th>\n      <th>qflag</th>\n      <th>weight1</th>\n      <th>weight1_freqwt</th>\n      <th>weight2</th>\n      <th>weight1a</th>\n      <th>weight1a_freqwt</th>\n      <th>weight_combo</th>\n      <th>weight_combo_freqwt</th>\n      <th>...</th>\n      <th>hcm2017q24_met_through_family</th>\n      <th>hcm2017q24_met_through_friend</th>\n      <th>hcm2017q24_met_through_as_nghbrs</th>\n      <th>hcm2017q24_met_as_through_cowork</th>\n      <th>w6_subject_race</th>\n      <th>interracial_5cat</th>\n      <th>partner_mother_yrsed</th>\n      <th>subject_mother_yrsed</th>\n      <th>partner_yrsed</th>\n      <th>subject_yrsed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2014039</td>\n      <td>Qualified</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.8945</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.277188</td>\n      <td>19240.0</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>White</td>\n      <td>no</td>\n      <td>12.0</td>\n      <td>14.0</td>\n      <td>12.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>2019003</td>\n      <td>Qualified</td>\n      <td>0.9078</td>\n      <td>71115.0</td>\n      <td>NaN</td>\n      <td>0.9026</td>\n      <td>70707.0</td>\n      <td>1.020621</td>\n      <td>70841.0</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>White</td>\n      <td>no</td>\n      <td>12.0</td>\n      <td>16.0</td>\n      <td>17.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>2145527</td>\n      <td>Qualified</td>\n      <td>0.7205</td>\n      <td>56442.0</td>\n      <td>NaN</td>\n      <td>0.7164</td>\n      <td>56121.0</td>\n      <td>0.810074</td>\n      <td>56227.0</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>White</td>\n      <td>no</td>\n      <td>9.0</td>\n      <td>7.5</td>\n      <td>14.0</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>2648857</td>\n      <td>Qualified</td>\n      <td>1.2597</td>\n      <td>98682.0</td>\n      <td>1.3507</td>\n      <td>1.2524</td>\n      <td>98110.0</td>\n      <td>0.418556</td>\n      <td>29052.0</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>White</td>\n      <td>no</td>\n      <td>16.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>2623465</td>\n      <td>Qualified</td>\n      <td>0.8686</td>\n      <td>68044.0</td>\n      <td>NaN</td>\n      <td>0.8636</td>\n      <td>67652.0</td>\n      <td>0.976522</td>\n      <td>67781.0</td>\n      <td>...</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>White</td>\n      <td>no</td>\n      <td>14.0</td>\n      <td>17.0</td>\n      <td>16.0</td>\n      <td>16.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 285 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "columns = ['w6_q21a_year', 'w6_q21a_month', 'w6_q21b_year', 'w6_q21b_month', 'w6_q21c_year', 'w6_q21c_month', 'w6_q21d_year', 'w6_q21d_month', 'w6_q19', 'ppage', 'w6_q9']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "CaseID                              0\nCASEID_NEW                          0\nqflag                               0\nweight1                           516\nweight1_freqwt                    516\n                                 ... \nrelationship_satisfaction_num     654\nrelationship_satisfaction_norm    663\nrelationship_duration             247\nrelationship_duration_norm        247\ncompatibility_score               763\nLength: 290, dtype: int64"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Mapping of categories to numerical values\n",
    "category_mapping = {\n",
    "    'Refused': np.nan,\n",
    "    'Excellent': 5,\n",
    "    'Good': 4,\n",
    "    'Fair': 3,\n",
    "    'Poor': 2,\n",
    "    'Very Poor': 1\n",
    "}\n",
    "\n",
    "# Replace the values in the Q34 column using the mapping\n",
    "df['satisfaction_score'] = df['Q34'].map(category_mapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "5.0    1706\n4.0     884\n3.0     202\n2.0      32\n1.0      23\nName: satisfaction_score, dtype: int64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['satisfaction_score'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'Categorical' and 'Categorical'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelationship_duration\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw6_q21b_year\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw6_q21a_year\u001B[39m\u001B[38;5;124m'\u001B[39m]) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m12\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw6_q21b_month\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw6_q21a_month\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:108\u001B[0m, in \u001B[0;36mOpsMixin.__sub__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sub__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__sub__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m--> 108\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[1;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/base.py:1295\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   1292\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(result, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:216\u001B[0m, in \u001B[0;36marithmetic_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001B[39;00m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;66;03m#  have already been called on `left` and `right`,\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    210\u001B[0m     should_extension_dispatch(left, right)\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001B[39;00m\n\u001B[1;32m    215\u001B[0m     \u001B[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     _bool_arith_check(op, left, right)\n",
      "\u001B[0;31mTypeError\u001B[0m: unsupported operand type(s) for -: 'Categorical' and 'Categorical'"
     ]
    }
   ],
   "source": [
    "df['relationship_duration'] = (df['w6_q21b_year'] - df['w6_q21a_year']) * 12 + (df['w6_q21b_month'] - df['w6_q21a_month'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0., 22., 11.,  4., 34., 35., 50., nan,  9.,  3.,  8.,  6., 13.,\n       10., 15., 43., 12., 17., 27., 25.,  2.,  7., 31., 40., 18., 29.,\n        1., 46., 20., 41., 49., 45., 62., 57., 28., 60.,  5., 30., 32.,\n       56., 36., 52., 48., 23., 44., 47., 53., 24., 14., 42., 54., 26.,\n       16., 59., 21., 38., 39., 33., 37., 65., 55., 75., 19., 64., 63.,\n       51., 58., 61., 67., 69., 66., 68., 70.])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentYear = 2017\n",
    "df[\"RelationshipDuration\"] = currentYear - df[\"w6_q21b_year\"]\n",
    "df[\"RelationshipDuration\"].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "satisfaction_mapping = {\n",
    "    'Refused': -1,\n",
    "    'Excellent': 5,\n",
    "    'Good': 4,\n",
    "    'Fair': 3,\n",
    "    'Poor': 2,\n",
    "    'Very Poor': 1\n",
    "}\n",
    "\n",
    "# Replace satisfaction categories with numerical values\n",
    "df['relationship_satisfaction_num'] = df['Q34'].map(satisfaction_mapping)\n",
    "\n",
    "# Normalize relationship satisfaction (excluding 'Refused' responses)\n",
    "df['relationship_satisfaction_norm'] = df[df['relationship_satisfaction_num'] != -1].apply(\n",
    "    lambda row: (row['relationship_satisfaction_num'] - 1) / 4, axis=1\n",
    ")\n",
    "\n",
    "# Calculate relationship duration in months\n",
    "df['relationship_duration'] = (df['w6_q21b_year'] - df['w6_q21a_year'])\n",
    "\n",
    "# Normalize relationship duration\n",
    "duration_min = df['relationship_duration'].min()\n",
    "duration_max = df['relationship_duration'].max()\n",
    "df['relationship_duration_norm'] = (df['relationship_duration'] - duration_min) / (duration_max - duration_min)\n",
    "\n",
    "# Calculate compatibility score\n",
    "df['compatibility_score'] = 0.6 * df['relationship_satisfaction_norm'] + 0.3 * df['relationship_duration_norm'] + 0.1 * df['w6_q19']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [
    {
     "data": {
      "text/plain": "True     2716\nFalse     794\nName: compatibility_score, dtype: int64"
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['compatibility_score'] < 0.8).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "0            NaN\n1       0.765455\n2       0.550000\n3            NaN\n4       0.700000\n          ...   \n3505    0.700000\n3506    0.455455\n3507    0.550000\n3508    0.555455\n3509    0.400000\nName: compatibility_score, Length: 3510, dtype: float64"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['compatibility_score']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "features = ['ppgender', 'ppethm', 'ppage', 'ppeduc', 'w6_q4', 'w6_q6b', 'w6_q9', 'w6_q10', 'w6_q6a']\n",
    "target = 'compatibility_score'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "dfClean = df[features + [target]].dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "cat_features = ['ppgender', 'ppethm', 'ppeduc', 'w6_q4', 'w6_q6b', 'w6_q10', 'w6_q6a']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "def encode_categorical_features(data, features):\n",
    "    \"\"\"Encode categorical features using one-hot encoding.\"\"\"\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoded_features = enc.fit_transform(data[features]).toarray()\n",
    "    encoded_feature_names = enc.get_feature_names_out(features)\n",
    "\n",
    "    df_encoded = pd.DataFrame(encoded_features, columns=encoded_feature_names, index=data.index)\n",
    "    data = pd.concat([data.drop(features, axis=1), df_encoded], axis=1)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "dfClean = encode_categorical_features(dfClean, cat_features)\n",
    "X = dfClean.drop(target, axis=1)\n",
    "y = dfClean[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.12588157155414\n",
      "MSE: 0.01584617005694007\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# EntraÃ®nement du modÃ¨le de rÃ©gression linÃ©aire\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# PrÃ©diction sur l'ensemble de test\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE: {mse}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "3428    0.005455\n3468    0.705455\n2905    0.705455\n3226    0.700000\n2052    0.550000\n          ...   \n2795    0.705455\n176     0.700000\n445     0.600000\n2634    0.550000\n1974    0.605455\nName: compatibility_score, Length: 825, dtype: float64"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "27    97\n28    92\n58    89\n55    85\n57    83\n      ..\n93     2\n89     2\n91     2\n92     1\n88     1\nName: ppage, Length: 76, dtype: int64"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ppage'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "data": {
      "text/plain": "['No (Not Latino or Hispanic)', NaN, 'Yes, Mexican, Mexican American, Chicano', 'Yes, Other Latino/Hispanic', 'Yes, Puerto Rican', 'Yes, Cuban', 'Refused']\nCategories (6, object): ['Refused' < 'No (Not Latino or Hispanic)' < 'Yes, Mexican, Mexican American, Chicano' < 'Yes, Puerto Rican' < 'Yes, Cuban' < 'Yes, Other Latino/Hispanic']"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['w6_q6a'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [
    "# Create custom datapoint\n",
    "custom_datapoint = {\n",
    "    'ppgender': 'Male',\n",
    "    'ppethm': 'White, Non-Hispanic',\n",
    "    'ppage': 22,\n",
    "    'ppeduc': 'Master\\'s degree',\n",
    "    'w6_q4': '[Partner Name] is Female',\n",
    "    'w6_q6b': 'Black, Non-Hispanic',\n",
    "    'w6_q6a': 'No (Not Latino or Hispanic)',\n",
    "    'w6_q9': 20,\n",
    "    'w6_q10': 'Bachelor\\'s degree'\n",
    "}\n",
    "\n",
    "# Convert to dataframe\n",
    "custom_datapoint = pd.DataFrame(custom_datapoint, index=[0])\n",
    "custom_datapoint = encode_categorical_features(custom_datapoint, cat_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "# Compare cols to X_train and fill missing cols with 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "for col in X_train.columns:\n",
    "    if col not in custom_datapoint.columns:\n",
    "        custom_datapoint[col] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "# Order cols to match X_train\n",
    "custom_datapoint = custom_datapoint[X_train.columns]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.57082051])"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(custom_datapoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
